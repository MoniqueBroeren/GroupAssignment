{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "source": [
    "#VERSIE 2 VAN TESTING2, Nienke en Ema hebben hier onze aanpassingen doorgevoerd, dus oude aanpassingen staan in vorige versie"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T09:49:33.341984Z",
     "start_time": "2024-05-31T09:49:33.338122Z"
    }
   },
   "source": [
    "#import needed libraries\n",
    "import pandas as pd\n",
    "import rdkit\n",
    "import main\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import Draw\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import shapiro"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T09:49:33.376762Z",
     "start_time": "2024-05-31T09:49:33.360013Z"
    }
   },
   "source": [
    "#test printing molecule\n",
    "smiles = ['COC(=O)c1c[nH]c2cc(OC(C)C)c(OC(C)C)cc2c1=O', \"COC(=O)c1c[nH]c2cc(OC(C)C)c(OC(C)C)cc2c1=O\"]\n",
    "\n",
    "mols = [Chem.MolFromSmiles(smi) for smi in smiles]\n",
    "Draw.MolsToGridImage(mols, molsPerRow=2, subImgSize=(200, 200))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T09:49:33.419151Z",
     "start_time": "2024-05-31T09:49:33.404779Z"
    }
   },
   "source": [
    "#import data\n",
    "data_raw = pd.read_csv('tested_molecules.csv')\n",
    "data_raw"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T09:49:46.776273Z",
     "start_time": "2024-05-31T09:49:33.428284Z"
    }
   },
   "source": [
    "# Create dataframe\n",
    "expanded_df = main.create_dataframe(data_raw)\n",
    "expanded_df.head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "source": [
    "# verwijderen van PKM2_inhibition en ERK2_inhibition, want dit zijn de labels en dit is enkel nodig om het deep learning model te trainen\n",
    "expanded_df = expanded_df.drop(columns = ['PKM2_inhibition','ERK2_inhibition'])\n",
    "expanded_df"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T09:49:46.782678Z",
     "start_time": "2024-05-31T09:49:46.778833Z"
    }
   },
   "source": [
    "expanded_df.describe()\n",
    "\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "source": [
    "# checken of er outliers zijn door boxplots te maken\n",
    "expanded_df.describe()\n",
    "\n",
    "# checken of we geen missing values hebben\n",
    "nan_counts = expanded_df.columns[expanded_df.isnull().any()].tolist()\n",
    "print(nan_counts)\n",
    "\n",
    "# checken of er lijsten zijn die enkel dezelfde waarde bevat\n",
    "non_variating_columns = expanded_df.columns[expanded_df.nunique()==1].tolist()\n",
    "print(len(non_variating_columns))\n",
    "\n",
    "# omdat de hele lijst geen variatie vertoont verwijderen we hem want dan kan er op basis van deze variabelen ook geen onderscheid worden gemaakt tussen de moleculen\n",
    "expanded_df.drop(columns = non_variating_columns, inplace = True)\n",
    "expanded_df.describe()\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "source": [
    "# Controleren op normaal verdeeldheid\n",
    "normality_results = main.check_normality(expanded_df.iloc[:,1:])\n",
    "\n",
    "# Print resultaten\n",
    "for column, p_value in normality_results.items():\n",
    "    if p_value > 0.05:\n",
    "        print(f\"Kolom {column} is normaal verdeeld (p-waarde = {p_value:.5f})\")\n",
    "print('Done')\n",
    "\n",
    "# geen enkele variabele is dus normaal verdeeld --> standard scaling is naar onze mening dus geen goed idee, wij zouden voor min-max gaan\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaled_array = scaler.fit_transform(expanded_df.iloc[:,1:])\n",
    "scaled_df = pd.DataFrame(scaled_array, columns=expanded_df.iloc[:,1:].columns)\n",
    "\n",
    "# Weergeven van de geschaalde DataFrame\n",
    "scaled_df.describe()\n",
    "\n",
    "# scaled_df heeft niet meer de SMILES erin staan"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "source": [
    "# plotten van min-max scaled values\n",
    "plt.figure(figsize=(40, 12))\n",
    "scaled_df.boxplot(rot=90)\n",
    "plt.title('Boxplot van elke variabele')\n",
    "plt.ylabel('Waarden (min-max geschaald)')\n",
    "plt.xlabel('Variabelen')\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T09:49:46.789416Z",
     "start_time": "2024-05-31T09:49:46.783693Z"
    }
   },
   "source": [
    "# Hier moeten nog de outliers uitgehaald worden\n",
    "# Function to calculate number of outliers in a column\n",
    "def count_outliers(column):\n",
    "    Q1 = column.quantile(0.25)\n",
    "    Q3 = column.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = ((column < lower_bound) | (column > upper_bound)).sum()\n",
    "    return outliers\n",
    "\n",
    "# Apply the function to each column\n",
    "outliers_per_column = expanded_df.iloc[:, 1:].apply(count_outliers)\n",
    "print(\"Number of outliers per column:\")\n",
    "print(outliers_per_column)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T09:49:50.990197Z",
     "start_time": "2024-05-31T09:49:46.792418Z"
    }
   },
   "source": [
    "# use PCA\n",
    "pca = PCA()\n",
    "pca.fit(scaled_df)\n",
    "\n",
    "\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T09:49:51.305756Z",
     "start_time": "2024-05-31T09:49:50.991199Z"
    }
   },
   "source": [
    "# MinMaxScaler\n",
    "\n",
    "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(range(1, len(cumulative_variance) + 1), cumulative_variance, alpha=0.5, align='center')\n",
    "\n",
    "plt.axhline(y=0.9,color='r',linestyle='-')\n",
    "plt.xlabel('Principal component (PC)')\n",
    "plt.ylabel('Cumulative Explained Variance (%)')\n",
    "plt.title('cumulative explained variance for each principal component')\n",
    "\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T09:49:51.684444Z",
     "start_time": "2024-05-31T09:49:51.678495Z"
    }
   },
   "source": [
    "# Kijken welke het belangrijkste is in pc1\n",
    "important_idx = np.argmax(np.abs(pca.components_[0]))\n",
    "important_feature = scaled_df.columns[important_idx]\n",
    "important_feature"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T09:49:51.693197Z",
     "start_time": "2024-05-31T09:49:51.686449Z"
    }
   },
   "source": [
    "# Kijken welke het minst belangrijkste is\n",
    "important_idx = np.argmin(np.abs(pca.components_[0]))\n",
    "important_feature = scaled_df.columns[important_idx]\n",
    "important_feature"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T09:49:51.699805Z",
     "start_time": "2024-05-31T09:49:51.694146Z"
    }
   },
   "source": [
    "# Nummer of Principal Components bij MinMaxScaling\n",
    "num_components = np.argmax(cumulative_variance >= 0.80) + 1\n",
    "num_components"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "source": [
    "# voor spearman gekozen want geen normality assumed\n",
    "correlation_matrix = expanded_df.iloc[:,1:].corr(method = 'spearman')\n",
    "\n",
    "# Maak de heatmap\n",
    "plt.figure(figsize=(60, 60))\n",
    "sns.heatmap(correlation_matrix, cmap='coolwarm', annot=False)\n",
    "plt.title('Correlatie tussen alle variabelen')\n",
    "plt.show()\n",
    "\n",
    "# wij denken dat een zo laag mogelijke correlatie beter is, omdat sterk gerelateerde variabelen geen extra informatie geven"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "source": [
    "# wij denken dat we vanaf hier aan stap 3 moeten beginnen en een model voor het deep learning gedeelte moeten \n",
    "#schrijven om te selecteren welke variabelen het belangrijkste zijn"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
